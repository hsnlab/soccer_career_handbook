{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#import category_encoders as ce\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "#from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import cross_validate, cross_val_predict\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import recall_score, precision_score, f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from numpy import mean\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "import operator\n",
    "import itertools\n",
    "import operator\n",
    "from itertools import islice\n",
    "import glob\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "#from xgboost import XGBClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.naive_bayes import GaussianNB \n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "#import pandasql as ps\n",
    "import matplotlib.pyplot as plt\n",
    "from fastdtw import fastdtw\n",
    "from matplotlib.pyplot import figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data read\n",
    "data = pd.read_excel('data_KPI.xlsx')\n",
    "del data['Unnamed: 0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>median</th>\n",
       "      <th>Q3</th>\n",
       "      <th>max</th>\n",
       "      <th>mean</th>\n",
       "      <th>mrate</th>\n",
       "      <th>qrate</th>\n",
       "      <th>maxrate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012</td>\n",
       "      <td>600</td>\n",
       "      <td>1800</td>\n",
       "      <td>120000</td>\n",
       "      <td>1964</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>1.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013</td>\n",
       "      <td>600</td>\n",
       "      <td>1800</td>\n",
       "      <td>144000</td>\n",
       "      <td>2075</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>1.388889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014</td>\n",
       "      <td>600</td>\n",
       "      <td>1800</td>\n",
       "      <td>144000</td>\n",
       "      <td>2129</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>1.388889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015</td>\n",
       "      <td>600</td>\n",
       "      <td>1800</td>\n",
       "      <td>144000</td>\n",
       "      <td>2161</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>1.388889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016</td>\n",
       "      <td>600</td>\n",
       "      <td>1800</td>\n",
       "      <td>144000</td>\n",
       "      <td>2184</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>1.388889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2017</td>\n",
       "      <td>600</td>\n",
       "      <td>1500</td>\n",
       "      <td>144000</td>\n",
       "      <td>2301</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.388889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2018</td>\n",
       "      <td>600</td>\n",
       "      <td>1800</td>\n",
       "      <td>216000</td>\n",
       "      <td>2902</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.925926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2019</td>\n",
       "      <td>600</td>\n",
       "      <td>1500</td>\n",
       "      <td>200000</td>\n",
       "      <td>2949</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  median    Q3     max  mean  mrate     qrate   maxrate\n",
       "0  2012     600  1800  120000  1964    1.0  0.833333  1.666667\n",
       "1  2013     600  1800  144000  2075    1.0  0.833333  1.388889\n",
       "2  2014     600  1800  144000  2129    1.0  0.833333  1.388889\n",
       "3  2015     600  1800  144000  2161    1.0  0.833333  1.388889\n",
       "4  2016     600  1800  144000  2184    1.0  0.833333  1.388889\n",
       "5  2017     600  1500  144000  2301    1.0  1.000000  1.388889\n",
       "6  2018     600  1800  216000  2902    1.0  0.833333  0.925926\n",
       "7  2019     600  1500  200000  2949    1.0  1.000000  1.000000"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Inflation calculation\n",
    "rates=[]\n",
    "years = [*range(2012,2020)]\n",
    "\n",
    "    \n",
    "for j in range(8):                           #Itt lehet játszani hogy 50 vagy 75 percentilis és melyik év\n",
    "    rates.append(np.percentile(data['Value'].loc[data['Year'] == 2019],50)/np.percentile(data['Value'].loc[data['Year'] == years[j]],50))\n",
    "    \n",
    "for k in range(8):\n",
    "    data.loc[data['Year'] == years[k], 'modded'] = round(data['Value']*rates[k]).astype(int)\n",
    "\n",
    "#Descriptive stats\n",
    "ev = []\n",
    "percentile = []\n",
    "maxim = []\n",
    "median = []\n",
    "mean = []\n",
    "year = list(range(2012,2020))\n",
    "\n",
    "for i in range(8):\n",
    "    ev.append(data.loc[data['Year'] == year[i]])\n",
    "\n",
    "for j in range(8):\n",
    "    percentile.append(np.percentile(ev[j]['modded'],75))\n",
    "    maxim.append(np.percentile(ev[j]['modded'],100))\n",
    "    median.append(np.median(ev[j]['modded']))\n",
    "    mean.append(np.mean(ev[j]['modded']))\n",
    "leiro = pd.DataFrame(list(zip(year, median, percentile, maxim, mean)), \n",
    "               columns =['year','median','Q3','max', 'mean'])\n",
    "\n",
    "leiro['median'] = leiro['median']/1000\n",
    "leiro['mrate'] = leiro['median'][7]/leiro['median']\n",
    "leiro['Q3'] = leiro['Q3']/1000\n",
    "leiro['qrate'] = leiro['Q3'][7]/leiro['Q3']\n",
    "leiro['max'] = leiro['max']/1000\n",
    "leiro['maxrate'] = leiro['max'][7]/leiro['max']\n",
    "leiro['mean']= leiro['mean']/1000\n",
    "\n",
    "leiro['median'] = leiro['median'].astype(int)\n",
    "leiro['Q3'] = leiro['Q3'].astype(int)\n",
    "leiro['max'] = leiro['max'].astype(int)\n",
    "leiro['mean'] = leiro['mean'].astype(int)\n",
    "\n",
    "leiro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#individual time series creation\n",
    "series = []\n",
    "grouped_df = data.groupby(\"ID\")\n",
    "for i in grouped_df:\n",
    "    series.append(i[1])\n",
    "\n",
    "#store players with 4+ years of data\n",
    "reduced = []\n",
    "for i in range(len(series)):\n",
    "    if len(series[i])>=4:\n",
    "        reduced.append(series[i])\n",
    "\n",
    "#selected and others ID collection\n",
    "joid = []\n",
    "roid = []\n",
    "for i in range(len(reduced)):\n",
    "    if reduced[i].Skill1.mean()>=80:\n",
    "        joid.append(reduced[i].ID[:1].values)\n",
    "    else:\n",
    "        roid.append(reduced[i].ID[:1].values)\n",
    "\n",
    "#selected and others individual time series      \n",
    "jolist = [] #selected\n",
    "rolist = [] #others\n",
    "for i in joid:\n",
    "    jolist.append(data.loc[data.ID==i[0]])\n",
    "    \n",
    "for i in roid:\n",
    "    rolist.append(data.loc[data.ID==i[0]])\n",
    "    \n",
    "#creating datasets from the groups\n",
    "selected = data[data.ID.isin(joid)].copy()\n",
    "others = data[data.ID.isin(roid)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#features = ['KPI_IsNational']\n",
    "#features = ['Inlf_Value']\n",
    "features = ['KPI_IsPL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1248\n",
      "8970\n"
     ]
    }
   ],
   "source": [
    "print(len(jolist))\n",
    "print(len(rolist))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DTW (to skip this long process, please load the distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#selected distances\n",
    "jodist = pd.DataFrame()\n",
    "for i in range(len(jolist)):\n",
    "    jolist[i]=jolist[i].reset_index(drop=True)\n",
    "    \n",
    "for j in features:\n",
    "    joranges=[]\n",
    "    for x in range(0,len(jolist)):\n",
    "        #print('A vizsgált: ', x)\n",
    "        for i in range(x, len(jolist)):\n",
    "            if i!=x:\n",
    "                d1 = jolist[x][j]\n",
    "                d2 = jolist[i][j]\n",
    "                distance = fastdtw(d1, d2)[0]\n",
    "                joranges.append(distance)\n",
    "                #print('The distance between the two time-series(',j,')  is %s' % distance)\n",
    "    jodist[j] = joranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#others distances\n",
    "rodist = pd.DataFrame()\n",
    "for i in range(len(rolist)):\n",
    "    rolist[i]=rolist[i].reset_index(drop=True)\n",
    "    \n",
    "for j in features:\n",
    "    roranges=[]\n",
    "    for x in range(0,len(rolist),8):\n",
    "        #print('A vizsgált: ', x)\n",
    "        for i in range(x, len(rolist),8):\n",
    "            if i!=x:\n",
    "                d1 = rolist[x][j]\n",
    "                d2 = rolist[i][j]\n",
    "                distance = fastdtw(d1, d2)[0]\n",
    "                roranges.append(distance)\n",
    "                #print('The distance between the two time-series(',j,')  is %s' % distance)\n",
    "    rodist[j] = roranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#between groups distances\n",
    "comd = pd.DataFrame()\n",
    "for i in range(len(rolist)):\n",
    "    rolist[i]=rolist[i].reset_index(drop=True)\n",
    "for i in range(len(jolist)):\n",
    "    jolist[i]=jolist[i].reset_index(drop=True)\n",
    "    \n",
    "for j in features:\n",
    "    ranges=[]\n",
    "    for x in range(0,len(jolist)):\n",
    "        #print('A vizsgált: ', x)\n",
    "        for i in range(0,len(rolist),8):\n",
    "                d1 = jolist[x][j]\n",
    "                d2 = rolist[i][j]\n",
    "                distance = fastdtw(d1, d2)[0]\n",
    "                ranges.append(distance)\n",
    "                #print('The distance between the two time-series(',j,')  is %s' % distance)\n",
    "    comd[j] = ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "jodist.to_csv('jodist_IsPL.csv')\n",
    "rodist.to_csv('rodist_IsPL.csv')\n",
    "comd.to_csv('comd_IsPL.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the DTW distances here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jodist=pd.read_csv('jodist_Skill1.csv')\n",
    "del jodist['Unnamed: 0']\n",
    "rodist=pd.read_csv('rodist_Skill1.csv')\n",
    "del rodist['Unnamed: 0']\n",
    "#comdist=pd.read_csv('comdist.csv')\n",
    "comd=pd.read_csv('comd_Skill1.csv')\n",
    "del comd['Unnamed: 0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "778128\n",
      "628881\n",
      "1400256\n"
     ]
    }
   ],
   "source": [
    "print(len(jodist))\n",
    "print(len(rodist))\n",
    "print(len(comd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best mean distance: 0.355\n",
      "Others mean distance: 0.436\n",
      "Between groups mean distance: 1.029\n"
     ]
    }
   ],
   "source": [
    "print('Best mean distance:', round(jodist.mean().values[0],3))\n",
    "print('Others mean distance:', round(rodist.mean().values[0],3))\n",
    "print('Between groups mean distance:', round(comd.mean().values[0],3))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
